{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc79f6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1. What is Web Scraping? Why is it Used? Give three areas where Web Scraping is used to get data.\n",
    "'''\n",
    "Web scraping is a way to collect data from the internet. It is used to collect large amounts of data which \n",
    "can be used for various data analyses. \n",
    "\n",
    "Three areas where web scraping is used to collect data:\n",
    "1) Customer sentiment analysis\n",
    "2) Price comparison sites\n",
    "3) Market research\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7c18a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2. What are the different methods used for Web Scraping?\n",
    "'''\n",
    "Different methods used for web scraping:\n",
    "1) Human copy-and-paste.\n",
    "2) Text pattern matching.\n",
    "3) HTTP programming.\n",
    "4) HTML parsing.\n",
    "5) DOM parsing.\n",
    "6) Vertical aggregation.\n",
    "7) Semantic annotation recognizing.\n",
    "8) Computer vision web-page analysis.\n",
    "9) Google Sheets\n",
    "10) XPath\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f48d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3. What is Beautiful Soup? Why is it used?\n",
    "'''\n",
    "Beautiful Soup is a Python library for web scraping by pulling data out of HTML and XML files.\n",
    "It is easy to use and learn and is faster. It works independently from browsers and requires less\n",
    "time to run. It is also easier to debug.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88545936",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4. Why is flask used in this Web Scraping project?\n",
    "'''\n",
    "Flask is used in scraping project to make a web application that does scraping instead of\n",
    "running the code. This way helps to share the URL of the application to others also. The user friendly \n",
    "interface makes scraping data easier.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f0e647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5. Write the names of AWS services used in this project. Also, explain the use of each service.\n",
    "'''\n",
    "AWS services used in this project are:\n",
    "1) AWS CodePipeline is a continuous delivery service you can use to model, visualize, and automate the\n",
    "steps required to release the software. We can quickly model and configure the different stages of a\n",
    "software release process.\n",
    "\n",
    "2) AWS Elastic Beanstalk is used to quickly deploy and manage applications in the AWS Cloud without\n",
    "having to learn about the infrastructure that runs those applications. It reduces management complexity\n",
    "without restricting choice or control. We can simply upload the application and  the details of capacity\n",
    "provisioning, load balancing, scaling, and application health monitoring are automatically handled.\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
